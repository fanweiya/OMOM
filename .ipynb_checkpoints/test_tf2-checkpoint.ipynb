{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 712588 images belonging to 266 classes.\n",
      "Found 277503 images belonging to 266 classes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ae03d484d8c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m grad_cam=GradCAMCallback(\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"activation_1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mclass_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from efficientnet.keras import EfficientNetB0,EfficientNetB1,EfficientNetB3,EfficientNetB4\n",
    "import keras\n",
    "import tf_explain\n",
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img\n",
    "from imutils import paths\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras import losses\n",
    "from losses import categorical_focal_loss\n",
    "import random\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "config = tf.compat.v1.ConfigProto()  \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import load_model\n",
    "from keras import initializers\n",
    "import itertools\n",
    "import os\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "from keras.layers import Concatenate\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams,font_manager\n",
    "from consinlr import CosineAnnealingScheduler\n",
    "from WRWD import *\n",
    "from CyclicalLearningRate_callback import *\n",
    "from SGDRScheduler import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense,Flatten,Input,Dropout,GlobalAveragePooling2D,GlobalMaxPooling2D,Lambda\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,LearningRateScheduler\n",
    "from keras.layers import Dense,Input,BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import multi_gpu_model\n",
    "import time\n",
    "from keras.callbacks import Callback\n",
    "from randaugment import *\n",
    "#from metrics import *\n",
    "from numpy.random import seed \n",
    "seed(1) \n",
    "tf.random.set_seed(2)\n",
    "def get_current_time():\n",
    "    time_stamp = time.time()\n",
    "    local_time = time.localtime(time_stamp)\n",
    "    str_time = time.strftime('%Y-%m-%d-%H:%M:%S', local_time)\n",
    "    return str_time\n",
    "\n",
    "img_augment = Rand_Augment()\n",
    "def random_augimage(p=0.5):\n",
    "    def aug_iamge(input_img):\n",
    "        aug_persion = np.random.rand()\n",
    "        if aug_persion < p:\n",
    "            return input_img\n",
    "        else:\n",
    "            input_img=img_to_array(img_augment(array_to_img(input_img)))\n",
    "            return input_img\n",
    "    return aug_iamge\n",
    "gpu_num=2\n",
    "label_smooh_rate=0.05\n",
    "Num_epochs=100\n",
    "backbone='TrainB4-newdata'\n",
    "batch_size = 64*gpu_num\n",
    "chnnel_number = 3\n",
    "root='/share_data/fanweiya/训练集cest分类-20200227_datasets_result/datasets_noextend'\n",
    "img_height = img_width = 256\n",
    "trainPath = os.path.join(root,'train_add500')\n",
    "valPath = os.path.join(root,'val')\n",
    "class_number = len(os.listdir(trainPath))\n",
    "weight_path='/root/CEST_weights/{}'.format(backbone)\n",
    "if not os.path.exists(weight_path):\n",
    "    os.makedirs(weight_path)\n",
    "weight_path=weight_path+'/model_'+get_current_time()\n",
    "if not os.path.exists(weight_path):\n",
    "    os.makedirs(weight_path)  \n",
    "totalTrain = len(list(paths.list_images(trainPath)))\n",
    "totalVal = len(list(paths.list_images(valPath)))     \n",
    "train_datagen = ImageDataGenerator(\n",
    "    fill_mode='constant',\n",
    "    cval=0,\n",
    "    rescale=1. / 255,\n",
    "    width_shift_range=np.random.choice(np.linspace(0, 0.1,5)),\n",
    "    height_shift_range=np.random.choice(np.linspace(0, 0.1,5)),\n",
    "    preprocessing_function=random_augimage()\n",
    "    )\n",
    "val_datagen = ImageDataGenerator(\n",
    "        #rotation_range=np.random.choice((0,45)),\n",
    "        #fill_mode='constant',\n",
    "        #cval=0,\n",
    "        rescale=1. / 255,\n",
    "        horizontal_flip=np.random.choice((True,False)),\n",
    "        vertical_flip=np.random.choice((True,False)))\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    trainPath,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    valPath,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "class_label=list(validation_generator.class_indices.keys())\n",
    "def save_labelfile(labelpath,label):\n",
    "    labeljs = os.path.join(labelpath,'label.js')\n",
    "    if not os.path.exists(labeljs):\n",
    "        try:\n",
    "            os.system(r\"touch {}\".format(labeljs))\n",
    "            f=open(labeljs,'w')\n",
    "            f.write(label)\n",
    "            f.close()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "save_labelfile(weight_path,class_label)\n",
    "'''\n",
    "'''\n",
    "input_tensor = Input((img_height,img_width,chnnel_number))\n",
    "efnet=EfficientNetB4(weights='/root/fanweiya/efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5',include_top=False,input_tensor=input_tensor)\n",
    "avgpool=GlobalAveragePooling2D()(efnet.output)\n",
    "drop1=Dropout(0.5)(avgpool)\n",
    "prediction_output=Dense(class_number,activation='softmax')(drop1)\n",
    "model=Model(efnet.inputs,prediction_output)\n",
    "#model.summary()\n",
    "\n",
    "# base_model=load_model('/share_data/CEST_weights/TrainB4-newdata/model_2020-03-06-09:58:16/jc_smr_0_12_valacc_0.7836_valloss_0.7498.h5')\n",
    "# base_model.layers.pop()\n",
    "# prediction_output=Dense(class_number,activation='softmax')(base_model.layers[-1].output)\n",
    "# model=Model(base_model.inputs,prediction_output)\n",
    "#plot_model(model,to_file=weight_path+'/model.png', show_shapes=True)\n",
    "\n",
    "Model= model\n",
    "#loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 100, 140, 180, and 190 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 190: \n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 180:  \n",
    "        lr *= 1e-3\n",
    "    elif epoch > 140: \n",
    "        lr *= 1e-2\n",
    "    elif epoch > 100: \n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "class ParallelModelCheckpoint(ModelCheckpoint):\n",
    "    def __init__(self,model,filepath, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='auto', period=1):\n",
    "        self.single_model = model\n",
    "        super(ParallelModelCheckpoint,self).__init__(filepath, monitor, verbose,save_best_only, save_weights_only,mode, period)\n",
    "    def set_model(self, model):\n",
    "        super(ParallelModelCheckpoint,self).set_model(self.single_model)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=10,verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5,verbose=1, mode='auto', epsilon=0.0001)\n",
    "cosin_lr=CosineAnnealingScheduler(T_max=10, eta_max=1e-3, eta_min=1e-6)\n",
    "WRWD_lr=WRWDScheduler(steps_per_epoch=np.ceil(totalTrain / batch_size), lr=0.001, wd_norm=0.01)\n",
    "SGDRS_lr=SGDRScheduler(min_lr=1e-5,max_lr=1e-2,steps_per_epoch=np.ceil(totalTrain / batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "Cyclic_lr = CyclicLR(base_lr=0.001, max_lr=0.006,step_size=np.ceil(totalTrain / batch_size), mode='triangular')\n",
    "checkpoint = ParallelModelCheckpoint(model,filepath=weight_path+'/smr_{}'.format(label_smooh_rate)+'_{epoch:02d}_valacc_{val_acc:.4f}_valloss_{val_loss:.4f}.h5',monitor='val_loss',save_best_only=True,verbose=1)\n",
    "tensorboard_log=TensorBoard(log_dir=weight_path+'/model_log',histogram_freq=1,write_images=True)\n",
    "def gen_val_data(datagen):\n",
    "    while True:\n",
    "        iamge,label = datagen.next()\n",
    "        return (iamge,label),np.argmax(label)\n",
    "        #print([iamge,label],np.argmax(label))\n",
    "def get_last_conv_name(models):\n",
    "    for layer in models.layers:\n",
    "        if 'conv' in layer.name:\n",
    "            name=layer.name\n",
    "    return name\n",
    "grad_cam=GradCAMCallback(\n",
    "        validation_data=gen_val_data(validation_generator)[0],\n",
    "        layer_name=get_last_conv_name(model),\n",
    "        class_index=gen_val_data(validation_generator)[1],\n",
    "        output_dir=weight_path)\n",
    "cbks1 = [early_stopping,checkpoint,lr_reduce]\n",
    "cbks = [early_stopping,checkpoint,lr_reduce,cosin_lr,lr_scheduler,tensorboard_log,grad_cam]\n",
    "\n",
    "for layer in Model.layers:  \n",
    "    layer.trainable = True\n",
    "Model.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smooh_rate),optimizer=optimizers.SGD(lr=lr_schedule(0),momentum = 0.9, nesterov = True),metrics=['accuracy'])\n",
    "#\n",
    "'''\n",
    "history=Model.fit_generator(train_generator,epochs=Num_epochs,\n",
    "                                   steps_per_epoch=totalTrain // batch_size,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   validation_steps=totalVal // batch_size,\n",
    "                                   use_multiprocessing = True,workers=256,class_weight='auto',\n",
    "                                   verbose=1,callbacks=cbks)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(val_acc))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.ylim(0, 1)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(weight_path+'/model-run-result1.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_name(models):\n",
    "    for layer in models.layers:\n",
    "        if 'conv' in layer.name:\n",
    "            name=layer.name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'top_conv'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_conv_name(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
